# Vision Transformer Attention Mechanism Benchmark

This repository, maintained by woodminus, is a comprehensive benchmarking of various attention mechanisms used in Vision Transformers. It not only provides a re-implementation but also furnishes a performance benchmark on parameters, FLOPs and CPU/GPU throughput of different attention mechanisms.

### Requirements

- Pytorch 1.8+
- timm
- ninja
- einops
- fvcore
- matplotlib

### Testing Environment

- NVIDIA RTX 3090
- Intel® Core™ i9-10900X CPU